{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae10d557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.20.0)\n",
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.8-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\krish\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\krish\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\krish\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\krish\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\krish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Downloading keras_tuner-1.4.8-py3-none-any.whl (129 kB)\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "\n",
      "   -------------------- ------------------- 1/2 [keras-tuner]\n",
      "   ---------------------------------------- 2/2 [keras-tuner]\n",
      "\n",
      "Successfully installed keras-tuner-1.4.8 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow keras-tuner pandas scikit-learn pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f5cdd",
   "metadata": {},
   "source": [
    "ðŸ”¥ PART 1 â€” ULTRA TABULAR (.CSV) AUTO HYPERPARAMETER TUNER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0c05f",
   "metadata": {},
   "source": [
    "âœ… Features\n",
    "\n",
    "This is now a serious structured-data deep learning tuner.\n",
    "\n",
    "Tuned:\n",
    "\n",
    "âœ… layers (1â€“6)\n",
    "\n",
    "âœ… neurons (32â€“1024)\n",
    "\n",
    "âœ… activation (relu / gelu / swish / elu)\n",
    "\n",
    "âœ… dropout\n",
    "\n",
    "âœ… batch norm\n",
    "\n",
    "âœ… L2 regularization\n",
    "\n",
    "âœ… optimizer (Adam / AdamW / RMSprop / Nadam)\n",
    "\n",
    "âœ… learning rate (log scale)\n",
    "\n",
    "âœ… gradient clipping\n",
    "\n",
    "âœ… label smoothing\n",
    "\n",
    "âœ… initializer\n",
    "\n",
    "âœ… batch \n",
    "\n",
    "âœ… early stopping\n",
    "\n",
    "âœ… LR scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ff41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "############################################\n",
    "# LOAD CSV\n",
    "############################################\n",
    "\n",
    "def load_csv(path):\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    # detect task\n",
    "    if \"float\" in str(y.dtype):\n",
    "        task = \"regression\"\n",
    "    else:\n",
    "        task = \"classification\"\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, task, len(np.unique(y)), X.shape[1]\n",
    "\n",
    "\n",
    "############################################\n",
    "# MODEL BUILDER\n",
    "############################################\n",
    "\n",
    "def build_csv_model(hp, input_dim, task, num_classes):\n",
    "\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = inputs\n",
    "\n",
    "    ##################################\n",
    "    # REGULARIZATION\n",
    "    ##################################\n",
    "\n",
    "    l2 = hp.Float(\"l2\", 1e-6, 1e-2, sampling=\"log\")\n",
    "\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 6)):\n",
    "\n",
    "        x = layers.Dense(\n",
    "            units=hp.Int(f\"units_{i}\", 32, 1024, step=32),\n",
    "            activation=hp.Choice(\n",
    "                \"activation\",\n",
    "                [\"relu\", \"gelu\", \"swish\", \"elu\"]\n",
    "            ),\n",
    "            kernel_initializer=hp.Choice(\n",
    "                \"initializer\",\n",
    "                [\"he_normal\", \"glorot_uniform\"]\n",
    "            ),\n",
    "            kernel_regularizer=regularizers.l2(l2)\n",
    "        )(x)\n",
    "\n",
    "        if hp.Boolean(\"batch_norm\"):\n",
    "            x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Dropout(\n",
    "            hp.Float(\"dropout\", 0.0, 0.5, step=0.1)\n",
    "        )(x)\n",
    "\n",
    "    ##################################\n",
    "    # OUTPUT\n",
    "    ##################################\n",
    "\n",
    "    if task == \"regression\":\n",
    "\n",
    "        outputs = layers.Dense(1)(x)\n",
    "        loss = \"mse\"\n",
    "        metrics = [\"mae\"]\n",
    "\n",
    "    else:\n",
    "\n",
    "        if num_classes == 2:\n",
    "\n",
    "            outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "            loss = keras.losses.BinaryCrossentropy(\n",
    "                label_smoothing=hp.Float(\"label_smoothing\", 0, 0.1)\n",
    "            )\n",
    "\n",
    "        else:\n",
    "\n",
    "            outputs = layers.Dense(num_classes,\n",
    "                                   activation=\"softmax\")(x)\n",
    "\n",
    "            loss = keras.losses.SparseCategoricalCrossentropy(\n",
    "                label_smoothing=hp.Float(\"label_smoothing\", 0, 0.1)\n",
    "            )\n",
    "\n",
    "        metrics = [\"accuracy\"]\n",
    "\n",
    "    ##################################\n",
    "    # OPTIMIZER\n",
    "    ##################################\n",
    "\n",
    "    lr = hp.Float(\"lr\", 1e-5, 1e-2, sampling=\"log\")\n",
    "\n",
    "    optimizer = hp.Choice(\"optimizer\", [\n",
    "        keras.optimizers.Adam(\n",
    "            learning_rate=lr,\n",
    "            clipnorm=hp.Float(\"clipnorm\", 1.0, 5.0)\n",
    "        ),\n",
    "        keras.optimizers.AdamW(learning_rate=lr),\n",
    "        keras.optimizers.RMSprop(learning_rate=lr),\n",
    "        keras.optimizers.Nadam(learning_rate=lr)\n",
    "    ])\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "############################################\n",
    "# PIPELINE\n",
    "############################################\n",
    "\n",
    "def run_csv_pipeline(csv_path):\n",
    "\n",
    "    X_train, X_test, y_train, y_test, task, num_classes, input_dim = load_csv(csv_path)\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        lambda hp: build_csv_model(hp, input_dim, task, num_classes),\n",
    "        objective=\"val_loss\",\n",
    "        max_epochs=40,\n",
    "        factor=3,\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    early = keras.callbacks.EarlyStopping(\n",
    "        patience=8,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        patience=4,\n",
    "        factor=0.3\n",
    "    )\n",
    "\n",
    "    tuner.search(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=80,\n",
    "        callbacks=[early, reduce_lr],\n",
    "        batch_size=kt.HyperParameters().Choice(\n",
    "            \"batch_size\",\n",
    "            [16, 32, 64, 128, 256]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "    model = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=80,\n",
    "        callbacks=[early, reduce_lr],\n",
    "        batch_size=best_hp.get(\"batch_size\")\n",
    "    )\n",
    "\n",
    "    model.evaluate(X_test, y_test)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d5e54",
   "metadata": {},
   "source": [
    "IMAGE CNN TUNER (KERAS TUNER ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1230cc7c",
   "metadata": {},
   "source": [
    "Tuned Properly:\n",
    "\n",
    "âœ… conv blocks (1â€“5)\n",
    "\n",
    "âœ… filters (32â€“512)\n",
    "\n",
    "âœ… kernel size\n",
    "\n",
    "âœ… batch norm\n",
    "\n",
    "âœ… dropout\n",
    "\n",
    "âœ… spatial dropout\n",
    "\n",
    "âœ… GAP vs Flatten\n",
    "\n",
    "âœ… dense head depth\n",
    "\n",
    "âœ… optimizer\n",
    "\n",
    "âœ… LR\n",
    "\n",
    "âœ… label smoothing\n",
    "\n",
    "âœ… augmentation toggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728ae542",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras_tuner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\krish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "############################################\n",
    "# LOAD IMAGES\n",
    "############################################\n",
    "\n",
    "def load_images(path):\n",
    "\n",
    "    train = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=123,\n",
    "        image_size=(128,128),\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    val = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=123,\n",
    "        image_size=(128,128),\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    return train.prefetch(tf.data.AUTOTUNE), val.prefetch(tf.data.AUTOTUNE), len(train.class_names)\n",
    "\n",
    "\n",
    "############################################\n",
    "# MODEL BUILDER\n",
    "############################################\n",
    "\n",
    "def build_image_model(hp, num_classes):\n",
    "\n",
    "    inputs = keras.Input(shape=(128,128,3))\n",
    "    x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "    if hp.Boolean(\"augment\"):\n",
    "        x = keras.Sequential([\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(0.1),\n",
    "            layers.RandomZoom(0.2),\n",
    "        ])(x)\n",
    "\n",
    "    ##################################\n",
    "    # CONV BLOCKS\n",
    "    ##################################\n",
    "\n",
    "    for i in range(hp.Int(\"conv_blocks\", 1, 5)):\n",
    "\n",
    "        x = layers.Conv2D(\n",
    "            filters=hp.Int(f\"filters_{i}\", 32, 512, step=32),\n",
    "            kernel_size=hp.Choice(\"kernel_size\",[3,5]),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        )(x)\n",
    "\n",
    "        if hp.Boolean(\"batch_norm\"):\n",
    "            x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D()(x)\n",
    "\n",
    "        if hp.Boolean(\"spatial_dropout\"):\n",
    "            x = layers.SpatialDropout2D(0.2)(x)\n",
    "\n",
    "    ##################################\n",
    "    # HEAD\n",
    "    ##################################\n",
    "\n",
    "    if hp.Boolean(\"global_avg_pool\"):\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "    else:\n",
    "        x = layers.Flatten()(x)\n",
    "\n",
    "    for i in range(hp.Int(\"dense_layers\",1,3)):\n",
    "        x = layers.Dense(\n",
    "            hp.Int(f\"dense_units_{i}\",64,512,64),\n",
    "            activation=\"relu\"\n",
    "        )(x)\n",
    "\n",
    "        x = layers.Dropout(\n",
    "            hp.Float(\"dropout\",0,0.6,0.1)\n",
    "        )(x)\n",
    "\n",
    "    outputs = layers.Dense(\n",
    "        num_classes,\n",
    "        activation=\"softmax\"\n",
    "    )(x)\n",
    "\n",
    "    lr = hp.Float(\"lr\",1e-5,1e-3,sampling=\"log\")\n",
    "\n",
    "    optimizer = hp.Choice(\"optimizer\",[\n",
    "        keras.optimizers.Adam(lr),\n",
    "        keras.optimizers.AdamW(lr)\n",
    "    ])\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(\n",
    "            label_smoothing=hp.Float(\"label_smoothing\",0,0.1)\n",
    "        ),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "############################################\n",
    "# PIPELINE\n",
    "############################################\n",
    "\n",
    "def run_image_pipeline(path):\n",
    "\n",
    "    train, val, num_classes = load_images(path)\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        lambda hp: build_image_model(hp, num_classes),\n",
    "        objective=\"val_accuracy\",\n",
    "        max_epochs=30,\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    early = keras.callbacks.EarlyStopping(\n",
    "        patience=6,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    tuner.search(\n",
    "        train,\n",
    "        validation_data=val,\n",
    "        epochs=60,\n",
    "        callbacks=[early]\n",
    "    )\n",
    "\n",
    "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "    model = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "    model.fit(\n",
    "        train,\n",
    "        validation_data=val,\n",
    "        epochs=60,\n",
    "        callbacks=[early]\n",
    "    )\n",
    "\n",
    "    model.evaluate(val)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333debe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Usage\n",
    "# CSV\n",
    "from csv_keras_tuner import run_csv_pipeline\n",
    "model = run_csv_pipeline(\"data.csv\")\n",
    "\n",
    "# Images\n",
    "from image_keras_tuner import run_image_pipeline\n",
    "model = run_image_pipeline(\"images/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
