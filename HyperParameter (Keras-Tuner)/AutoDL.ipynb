{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ec32742",
   "metadata": {},
   "source": [
    "TABULAR AUTO DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91508b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "\n",
    "class AutoDLTabular:\n",
    "\n",
    "    def __init__(self, csv_path):\n",
    "        self.csv_path = csv_path\n",
    "\n",
    "\n",
    "    ################################################\n",
    "    # LOAD DATA\n",
    "    ################################################\n",
    "\n",
    "    def load(self):\n",
    "\n",
    "        df = pd.read_csv(self.csv_path)\n",
    "\n",
    "        X = df.iloc[:, :-1]\n",
    "        y = df.iloc[:, -1]\n",
    "\n",
    "        # detect task\n",
    "        if \"float\" in str(y.dtype):\n",
    "            self.task = \"regression\"\n",
    "        else:\n",
    "            self.task = \"classification\"\n",
    "\n",
    "        if self.task == \"classification\":\n",
    "            self.encoder = LabelEncoder()\n",
    "            y = self.encoder.fit_transform(y)\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        X = self.scaler.fit_transform(X)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2\n",
    "        )\n",
    "\n",
    "        self.input_dim = X.shape[1]\n",
    "        self.num_classes = len(np.unique(y))\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "    ################################################\n",
    "    # MODEL BUILDER\n",
    "    ################################################\n",
    "\n",
    "    def build_model(self, hp):\n",
    "\n",
    "        inputs = keras.Input(shape=(self.input_dim,))\n",
    "        x = inputs\n",
    "\n",
    "        regularizer = regularizers.l2(\n",
    "            hp.Float(\"l2\", 1e-6, 1e-2, sampling=\"log\")\n",
    "        )\n",
    "\n",
    "        for i in range(hp.Int(\"layers\", 1, 8)):\n",
    "\n",
    "            units = hp.Int(f\"units_{i}\", 16, 1024, step=16)\n",
    "\n",
    "            dense = layers.Dense(\n",
    "                units,\n",
    "                activation=hp.Choice(\n",
    "                    \"activation\",\n",
    "                    [\"relu\", \"gelu\", \"selu\", \"swish\"]\n",
    "                ),\n",
    "                kernel_initializer=hp.Choice(\n",
    "                    \"initializer\",\n",
    "                    [\"he_normal\", \"glorot_uniform\"]\n",
    "                ),\n",
    "                kernel_regularizer=regularizer\n",
    "            )(x)\n",
    "\n",
    "            if hp.Boolean(\"batch_norm\"):\n",
    "                dense = layers.BatchNormalization()(dense)\n",
    "\n",
    "            dense = layers.Dropout(\n",
    "                hp.Float(\"dropout\", 0.0, 0.5, step=0.05)\n",
    "            )(dense)\n",
    "\n",
    "            # optional residual\n",
    "            if hp.Boolean(\"residual\") and dense.shape[-1] == x.shape[-1]:\n",
    "                x = layers.Add()([x, dense])\n",
    "            else:\n",
    "                x = dense\n",
    "\n",
    "        ###################################\n",
    "        # OUTPUT\n",
    "        ###################################\n",
    "\n",
    "        if self.task == \"regression\":\n",
    "\n",
    "            outputs = layers.Dense(1)(x)\n",
    "            loss = \"mse\"\n",
    "            metrics = [\"mae\"]\n",
    "\n",
    "        else:\n",
    "\n",
    "            if self.num_classes == 2:\n",
    "                outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "                loss = keras.losses.BinaryCrossentropy(\n",
    "                    label_smoothing=hp.Float(\n",
    "                        \"label_smooth\", 0, 0.1\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                outputs = layers.Dense(\n",
    "                    self.num_classes,\n",
    "                    activation=\"softmax\"\n",
    "                )(x)\n",
    "\n",
    "                loss = keras.losses.SparseCategoricalCrossentropy(\n",
    "                    label_smoothing=hp.Float(\n",
    "                        \"label_smooth\", 0, 0.1\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            metrics = [\"accuracy\"]\n",
    "\n",
    "        ###################################\n",
    "        # OPTIMIZER\n",
    "        ###################################\n",
    "\n",
    "        lr = hp.Float(\"lr\", 1e-5, 1e-2, sampling=\"log\")\n",
    "\n",
    "        optimizer = hp.Choice(\"optimizer\", [\n",
    "            keras.optimizers.Adam(\n",
    "                lr,\n",
    "                clipnorm=hp.Float(\"clipnorm\", 0.5, 5)\n",
    "            ),\n",
    "            keras.optimizers.AdamW(lr),\n",
    "            keras.optimizers.RMSprop(lr),\n",
    "        ])\n",
    "\n",
    "        model = keras.Model(inputs, outputs)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    ################################################\n",
    "    # TRAIN\n",
    "    ################################################\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = self.load()\n",
    "\n",
    "        tuner = kt.Hyperband(\n",
    "            self.build_model,\n",
    "            objective=\"val_loss\",\n",
    "            max_epochs=50,\n",
    "            factor=3,\n",
    "            overwrite=True\n",
    "        )\n",
    "\n",
    "        early = keras.callbacks.EarlyStopping(\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "            patience=5,\n",
    "            factor=0.3\n",
    "        )\n",
    "\n",
    "        tuner.search(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            validation_split=0.2,\n",
    "            epochs=100,\n",
    "            callbacks=[early, reduce_lr],\n",
    "            batch_size=kt.HyperParameters().Choice(\n",
    "                \"batch_size\", [16,32,64,128,256]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "        self.model = tuner.hypermodel.build(self.best_hp)\n",
    "\n",
    "        self.model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            validation_split=0.2,\n",
    "            epochs=100,\n",
    "            callbacks=[early, reduce_lr],\n",
    "            batch_size=self.best_hp.get(\"batch_size\")\n",
    "        )\n",
    "\n",
    "        self.test_data = (X_test, y_test)\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        return self.model.evaluate(*self.test_data)\n",
    "\n",
    "\n",
    "    def save(self, name=\"tabular_model\"):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba03e8",
   "metadata": {},
   "source": [
    "IMAGE AUTO DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class AutoDLImage:\n",
    "\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    # LOAD\n",
    "    #########################################\n",
    "\n",
    "    def load(self):\n",
    "\n",
    "        img_size = (hp_size := 128)\n",
    "\n",
    "        train = tf.keras.utils.image_dataset_from_directory(\n",
    "            self.data_dir,\n",
    "            validation_split=0.2,\n",
    "            subset=\"training\",\n",
    "            seed=123,\n",
    "            image_size=(hp_size, hp_size),\n",
    "            batch_size=32\n",
    "        )\n",
    "\n",
    "        val = tf.keras.utils.image_dataset_from_directory(\n",
    "            self.data_dir,\n",
    "            validation_split=0.2,\n",
    "            subset=\"validation\",\n",
    "            seed=123,\n",
    "            image_size=(hp_size, hp_size),\n",
    "            batch_size=32\n",
    "        )\n",
    "\n",
    "        self.num_classes = len(train.class_names)\n",
    "\n",
    "        return train.prefetch(tf.data.AUTOTUNE), val.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    # MODEL\n",
    "    #########################################\n",
    "\n",
    "    def build_model(self, hp):\n",
    "\n",
    "        inputs = keras.Input(shape=(128,128,3))\n",
    "\n",
    "        x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "        if hp.Boolean(\"augment\"):\n",
    "\n",
    "            x = keras.Sequential([\n",
    "                layers.RandomFlip(\"horizontal\"),\n",
    "                layers.RandomRotation(0.1),\n",
    "                layers.RandomZoom(0.2),\n",
    "            ])(x)\n",
    "\n",
    "        ###################################\n",
    "        # CONV BLOCKS\n",
    "        ###################################\n",
    "\n",
    "        for i in range(hp.Int(\"conv_blocks\",1,5)):\n",
    "\n",
    "            filters = hp.Int(f\"filters_{i}\",32,512,32)\n",
    "\n",
    "            if hp.Boolean(\"separable\"):\n",
    "                x = layers.SeparableConv2D(\n",
    "                    filters,\n",
    "                    kernel_size=hp.Choice(\n",
    "                        \"kernel\",[3,5]\n",
    "                    ),\n",
    "                    activation=\"relu\",\n",
    "                    padding=\"same\"\n",
    "                )(x)\n",
    "            else:\n",
    "                x = layers.Conv2D(\n",
    "                    filters,\n",
    "                    3,\n",
    "                    activation=\"relu\",\n",
    "                    padding=\"same\"\n",
    "                )(x)\n",
    "\n",
    "            if hp.Boolean(\"bn\"):\n",
    "                x = layers.BatchNormalization()(x)\n",
    "\n",
    "            x = layers.MaxPooling2D()(x)\n",
    "\n",
    "            if hp.Boolean(\"spatial_dropout\"):\n",
    "                x = layers.SpatialDropout2D(0.2)(x)\n",
    "\n",
    "        ###################################\n",
    "        # HEAD\n",
    "        ###################################\n",
    "\n",
    "        if hp.Boolean(\"global_pool\"):\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        else:\n",
    "            x = layers.Flatten()(x)\n",
    "\n",
    "        for i in range(hp.Int(\"dense\",1,3)):\n",
    "            x = layers.Dense(\n",
    "                hp.Int(f\"dense_units_{i}\",64,512,64),\n",
    "                activation=\"relu\"\n",
    "            )(x)\n",
    "\n",
    "            x = layers.Dropout(\n",
    "                hp.Float(\"drop\",0,0.6,0.1)\n",
    "            )(x)\n",
    "\n",
    "        outputs = layers.Dense(\n",
    "            self.num_classes,\n",
    "            activation=\"softmax\"\n",
    "        )(x)\n",
    "\n",
    "        lr = hp.Float(\"lr\",1e-5,1e-3,sampling=\"log\")\n",
    "\n",
    "        optimizer = hp.Choice(\"opt\",[\n",
    "            keras.optimizers.Adam(lr),\n",
    "            keras.optimizers.AdamW(lr)\n",
    "        ])\n",
    "\n",
    "        model = keras.Model(inputs, outputs)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    # TRAIN\n",
    "    #########################################\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        train, val = self.load()\n",
    "\n",
    "        tuner = kt.Hyperband(\n",
    "            self.build_model,\n",
    "            objective=\"val_accuracy\",\n",
    "            max_epochs=30,\n",
    "            overwrite=True\n",
    "        )\n",
    "\n",
    "        early = keras.callbacks.EarlyStopping(\n",
    "            patience=7,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        tuner.search(\n",
    "            train,\n",
    "            validation_data=val,\n",
    "            epochs=50,\n",
    "            callbacks=[early]\n",
    "        )\n",
    "\n",
    "        self.best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "        self.model = tuner.hypermodel.build(self.best_hp)\n",
    "\n",
    "        self.model.fit(\n",
    "            train,\n",
    "            validation_data=val,\n",
    "            epochs=50,\n",
    "            callbacks=[early]\n",
    "        )\n",
    "\n",
    "        self.val = val\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        return self.model.evaluate(self.val)\n",
    "\n",
    "\n",
    "    def save(self, name=\"image_model\"):\n",
    "        self.model.save(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⭐ HOW TO USE\n",
    "# 1️⃣ Tabular / Text\n",
    "from auto_dl import AutoDL\n",
    "\n",
    "trainer = AutoDL(\"data.csv\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "trainer.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42413ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⭐ 2️⃣ Image\n",
    "trainer = AutoDL(\"images/\")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
